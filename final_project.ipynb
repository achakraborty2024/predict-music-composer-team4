{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bach: ['F3', 'A3', 'C4', 'F4', 'A4', 'C4', 'F4', 'A4', 'F3', 'A3']...\n",
      "Beethoven: ['0.3.7', 'C5', 'E-5', 'D5', '7.11.2', 'G4', '7.9.11', '0.2', 'E5', '4.7.10.0']...\n",
      "Chopin: ['10.3', '10.3', '10.3', '8.0', '10.3', '8.0', '10.3', 'E-5', '10.3', '10.3']...\n",
      "Mozart: ['G4', 'C5', 'C5', 'B4', 'C5', 'D5', 'D5', 'C5', 'D5', 'E5']...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from music21 import converter, instrument, note, chord\n",
    "import warnings\n",
    "\n",
    "# Hiding pesky warnings about missing instrument info in MIDI files\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='music21')\n",
    "\n",
    "# Function to extract notes and chords from a MIDI file\n",
    "def extract_notes_and_chords(file_path):\n",
    "    notes = []\n",
    "    midi = converter.parse(file_path)\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    if parts:  # file has instrument parts\n",
    "        notes_to_parse = parts.parts[0].recurse()\n",
    "    else:  # file has notes in a flat structure\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes\n",
    "\n",
    "# Path to your dataset\n",
    "dataset_path = 'C:/Users/Mohammad/Desktop/Final_project'\n",
    "\n",
    "# Dictionary to hold the notes and chords for each composer\n",
    "composer_notes = {'Bach': [], 'Beethoven': [], 'Chopin': [], 'Mozart': []}\n",
    "\n",
    "# Iterate through each composer's folder\n",
    "for composer in composer_notes.keys():\n",
    "    folder_path = os.path.join(dataset_path, composer)\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.mid'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            notes = extract_notes_and_chords(file_path)\n",
    "            composer_notes[composer].extend(notes)\n",
    "\n",
    "# Print sample notes and chords\n",
    "for composer, notes in composer_notes.items():\n",
    "    print(f\"{composer}: {notes[:10]}...\")\n",
    "\n",
    "# Save extracted notes and chords for further use\n",
    "np.save('composer_notes.npy', composer_notes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Notes and Chords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bach: [900, 841, 867, 901, 842, 867, 901, 842, 900, 841]...\n",
      "Beethoven: [58, 868, 882, 875, 648, 914, 687, 21, 889, 466]...\n",
      "Chopin: [199, 199, 199, 697, 199, 697, 199, 882, 199, 199]...\n",
      "Mozart: [914, 868, 868, 854, 868, 875, 875, 868, 875, 889]...\n"
     ]
    }
   ],
   "source": [
    "# Flatten all notes and chords\n",
    "all_notes = []\n",
    "for notes in composer_notes.values():\n",
    "    all_notes.extend(notes)\n",
    "\n",
    "# Create a sorted list of unique notes and chords\n",
    "unique_notes = sorted(set(all_notes))\n",
    "\n",
    "# Create a dictionary to map notes and chords to integers\n",
    "note_to_int = {note: number for number, note in enumerate(unique_notes)}\n",
    "\n",
    "# Convert notes and chords to integers\n",
    "composer_sequences = {composer: [note_to_int[note] for note in notes] for composer, notes in composer_notes.items()}\n",
    "\n",
    "# Save mappings and sequences\n",
    "np.save('note_to_int.npy', note_to_int)\n",
    "np.save('composer_sequences.npy', composer_sequences)\n",
    "\n",
    "# Print sample encoded sequences\n",
    "for composer, sequence in composer_sequences.items():\n",
    "    print(f\"{composer}: {sequence[:10]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input Sequences and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequences shape: (464657, 100)\n",
      "Labels shape: (464657,)\n"
     ]
    }
   ],
   "source": [
    "# Define the sequence length\n",
    "sequence_length = 100\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "labels = []\n",
    "label_map = {'Bach': 0, 'Beethoven': 1, 'Chopin': 2, 'Mozart': 3}\n",
    "\n",
    "for composer, sequence in composer_sequences.items():\n",
    "    for i in range(len(sequence) - sequence_length):\n",
    "        # Extract the sequence of notes and chords\n",
    "        input_seq = sequence[i:i + sequence_length]\n",
    "        # The label is the next note/chord\n",
    "        label = sequence[i + sequence_length]\n",
    "        \n",
    "        input_sequences.append(input_seq)\n",
    "        labels.append(label_map[composer])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f\"Input sequences shape: {input_sequences.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building | LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_22 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m117,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_21 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Embedding\n",
    "\n",
    "# Explicit input shape declaration\n",
    "input_shape = (sequence_length, )\n",
    "embedding_input = Input(shape=input_shape)\n",
    "\n",
    "# Define the embedding layer without using input_length\n",
    "embedding_layer = Embedding(input_dim=len(unique_notes), output_dim=128)(embedding_input)\n",
    "\n",
    "# Define LSTM layers\n",
    "lstm_out1 = LSTM(128, return_sequences=True)(embedding_layer)\n",
    "dropout_out1 = Dropout(0.3)(lstm_out1)\n",
    "lstm_out2 = LSTM(128)(dropout_out1)\n",
    "dropout_out2 = Dropout(0.3)(lstm_out2)\n",
    "\n",
    "# Define output layer\n",
    "output = Dense(4, activation='softmax')(dropout_out2)\n",
    "\n",
    "# Build and compile the model\n",
    "lstm_model = Model(inputs=embedding_input, outputs=output)\n",
    "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "lstm_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5809/5809\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 112ms/step - accuracy: 0.8164 - loss: 0.5086 - val_accuracy: 0.0186 - val_loss: 6.8116\n",
      "Epoch 2/20\n",
      "\u001b[1m 997/5809\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:00\u001b[0m 100ms/step - accuracy: 0.9793 - loss: 0.0669"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "history = lstm_model.fit(input_sequences, labels, epochs=20, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the model for future use\n",
    "lstm_model.save('composer_lstm_model.h5')\n",
    "\n",
    "# Plot the training and validation accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
